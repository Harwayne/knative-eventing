# Copyright 2018 The Knative Authors
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

apiVersion: eventing.knative.dev/v1alpha1
kind: ClusterProvisioner
metadata:
  name: in-memory-channel
spec:
  reconciles:
    group: eventing.knative.dev/v1alpha1
    kind: Channel

---

apiVersion: v1
kind: ServiceAccount
metadata:
  name: in-memory-channel-controller
  namespace: knative-eventing

---

apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: in-memory-channel-controller
rules:
  - apiGroups:
      - eventing.knative.dev
    resources:
      - channels
      - clusterprovisioners
    verbs:
      - get
      - list
      - watch
      - update
  - apiGroups:
      - "" # Core API group.
    resources:
      - configmaps
      - services
    verbs:
      - get
      - list
      - watch
      - create
  - apiGroups:
      - "" # Core API Group.
    resources:
      - configmaps
    resourceNames:
      - in-memory-channel-dispatcher-config-map
    verbs:
      - update
  - apiGroups:
      - networking.istio.io
    resources:
      - virtualservices
    verbs:
      - get
      - list
      - watch
      - create

---

apiVersion: rbac.authorization.k8s.io/v1beta1
kind: ClusterRoleBinding
metadata:
  name: in-memory-channel-controller
  namespace: knative-eventing
subjects:
  - kind: ServiceAccount
    name: in-memory-channel-controller
    namespace: knative-eventing
roleRef:
  kind: ClusterRole
  name: in-memory-channel-controller
  apiGroup: rbac.authorization.k8s.io

---

apiVersion: apps/v1beta1
kind: Deployment
metadata:
  name: in-memory-channel-controller
  namespace: knative-eventing
spec:
  replicas: 1
  selector:
    matchLabels: &labels
      clusterProvisioner: in-memory-channel
      role: controller
  template:
    metadata:
      labels: *labels
    spec:
      serviceAccountName: in-memory-channel-controller
      containers:
        - name: controller
          image: github.com/knative/eventing/pkg/controller/eventing/inmemory/controller

---

apiVersion: v1
kind: ServiceAccount
metadata:
  name: in-memory-channel-dispatcher
  namespace: knative-eventing

---

apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: in-memory-channel-dispatcher
  namespace: knative-eventing
rules:
  - apiGroups:
      - "" # Core API group.
    resources:
      - configmaps
    verbs:
      - get
      - list
      - watch

---

apiVersion: rbac.authorization.k8s.io/v1beta1
kind: ClusterRoleBinding
metadata:
  name: in-memory-channel-dispatcher
  namespace: knative-eventing
subjects:
  - kind: ServiceAccount
    name: in-memory-channel-dispatcher
    namespace: knative-eventing
roleRef:
  kind: ClusterRole
  name: in-memory-channel-dispatcher
  apiGroup: rbac.authorization.k8s.io

---

apiVersion: apps/v1beta1
kind: Deployment
metadata:
  name: in-memory-channel-dispatcher
  namespace: knative-eventing
spec:
  replicas: 1
  selector:
    matchLabels: &labels
      clusterProvisioner: in-memory-channel
      role: dispatcher
  template:
    metadata:
      annotations:
        sidecar.istio.io/inject: "true"
      labels: *labels
    spec:
      serviceAccountName: in-memory-channel-dispatcher
      containers:
        - name: dispatcher
          image: github.com/knative/eventing/cmd/fanoutsidecar
          args:
            - --sidecar_port=8080
            - --config_map_noticer=watcher
            - --config_map_namespace=knative-eventing
            - --config_map_name=in-memory-channel-dispatcher-config-map

---

# From here to the end of the file is essentially a copied version of
# https://github.com/knative/serving/blob/master/config/202-gateway.yaml, with the names and labels
# changed. It also switches the Service from LoadBalancer -> ClusterIP so that it cannot be
# reached from outside the cluster.
#
# Ideally we would not copy paste this much code, which has to stay in-sync with Istio itself.
#
# Overall we are createing a Gateway, the Service that backs it, the Deployment that backs that
# Service, and the Autoscaler that scales the Deployment.

apiVersion: networking.istio.io/v1alpha3
kind: Gateway
metadata:
  name: knative-eventing-private-ingressgateway
  namespace: istio-system
spec:
  selector:
    knative-eventing: private-ingressgateway
  servers:
  - port:
      number: 80
      name: http
      protocol: HTTP
    hosts:
    - "*"
  - port:
      number: 443
      name: https
      protocol: HTTPS
    hosts:
    - "*"
    tls:
      mode: PASSTHROUGH

---


apiVersion: v1
kind: Service
metadata:
  name: knative-eventing-private-ingressgateway
  namespace: istio-system
  annotations:
  labels:
    chart: gateways-1.0.1
    release: RELEASE-NAME
    heritage: Tiller
    app: knative-eventing-private-ingressgateway
    knative-eventing: private-ingressgateway
spec:
  type: ClusterIP
  selector:
    app: knative-eventing-private-ingressgateway
    knative-eventing: private-ingressgateway
  ports:
  -
    name: http2
    port: 80
    targetPort: 80
  -
    name: https
    port: 443
  -
    name: tcp
    port: 31400
  -
    name: tcp-pilot-grpc-tls
    port: 15011
    targetPort: 15011
  -
    name: tcp-citadel-grpc-tls
    port: 8060
    targetPort: 8060
  -
    name: tcp-dns-tls
    port: 853
    targetPort: 853
  -
    name: http2-prometheus
    port: 15030
    targetPort: 15030
  -
    name: http2-grafana
    port: 15031
    targetPort: 15031
---
# This is the corresponding Deployment to backed the aforementioned Service.
apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: knative-eventing-private-ingressgateway
  namespace: istio-system
  labels:
    chart: gateways-1.0.1
    release: RELEASE-NAME
    heritage: Tiller
    app: knative-eventing-private-ingressgateway
    knative-eventing: private-ingressgateway
spec:
  replicas: 1
  selector:
    matchLabels: &labels
      app: knative-eventing-private-ingressgateway
      knative-eventing: private-ingressgateway
  template:
    metadata:
      labels: *labels
      annotations:
        sidecar.istio.io/inject: "false"
        scheduler.alpha.kubernetes.io/critical-pod: ""
    spec:
      serviceAccountName: istio-ingressgateway-service-account
      containers:
      - name: istio-proxy
        image: "docker.io/istio/proxyv2:1.0.2"
        imagePullPolicy: IfNotPresent
        ports:
        - containerPort: 80
        - containerPort: 443
        - containerPort: 31400
        - containerPort: 15011
        - containerPort: 8060
        - containerPort: 853
        - containerPort: 15030
        - containerPort: 15031
        args:
        - proxy
        - router
        - -v
        - "2"
        - --discoveryRefreshDelay
        - '1s' #discoveryRefreshDelay
        - --drainDuration
        - '45s' #drainDuration
        - --parentShutdownDuration
        - '1m0s' #parentShutdownDuration
        - --connectTimeout
        - '10s' #connectTimeout
        - --serviceCluster
        - knative-ingressgateway
        - --zipkinAddress
        - zipkin:9411
        - --statsdUdpAddress
        - istio-statsd-prom-bridge:9125
        - --proxyAdminPort
        - "15000"
        - --controlPlaneAuthPolicy
        - NONE
        - --discoveryAddress
        - istio-pilot:8080
        resources:
          requests:
            cpu: 10m

        env:
        - name: POD_NAME
          valueFrom:
            fieldRef:
              apiVersion: v1
              fieldPath: metadata.name
        - name: POD_NAMESPACE
          valueFrom:
            fieldRef:
              apiVersion: v1
              fieldPath: metadata.namespace
        - name: INSTANCE_IP
          valueFrom:
            fieldRef:
              apiVersion: v1
              fieldPath: status.podIP
        - name: ISTIO_META_POD_NAME
          valueFrom:
            fieldRef:
              fieldPath: metadata.name
        volumeMounts:
        - name: istio-certs
          mountPath: /etc/certs
          readOnly: true
        - name: ingressgateway-certs
          mountPath: "/etc/istio/ingressgateway-certs"
          readOnly: true
        - name: ingressgateway-ca-certs
          mountPath: "/etc/istio/ingressgateway-ca-certs"
          readOnly: true
      volumes:
      - name: istio-certs
        secret:
          secretName: istio.istio-ingressgateway-service-account
          optional: true
      - name: ingressgateway-certs
        secret:
          secretName: "istio-ingressgateway-certs"
          optional: true
      - name: ingressgateway-ca-certs
        secret:
          secretName: "istio-ingressgateway-ca-certs"
          optional: true
      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
            - matchExpressions:
              - key: beta.kubernetes.io/arch
                operator: In
                values:
                - amd64
                - ppc64le
                - s390x
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 2
            preference:
              matchExpressions:
              - key: beta.kubernetes.io/arch
                operator: In
                values:
                - amd64
          - weight: 2
            preference:
              matchExpressions:
              - key: beta.kubernetes.io/arch
                operator: In
                values:
                - ppc64le
          - weight: 2
            preference:
              matchExpressions:
              - key: beta.kubernetes.io/arch
                operator: In
                values:
                - s390x
---

# This is the horizontal pod autoscaler to make sure the ingress Pods
# scale up to meet traffic demand.
#
apiVersion: autoscaling/v2beta1
kind: HorizontalPodAutoscaler
metadata:
  name: knative-eventing-private-ingressgateway
  namespace: istio-system
spec:
  # TODO(1411): Document/fix this.  We are choosing an arbitrary 10 here.
  maxReplicas: 10
  minReplicas: 1
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: knative-eventing-private-ingressgateway
  metrics:
  - type: Resource
    resource:
      name: cpu
      targetAverageUtilization: 60
